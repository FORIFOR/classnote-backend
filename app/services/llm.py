import os
import asyncio
import json
from typing import List, Optional, Any

# Lazy import for vertexai to prevent build/startup crashes if credentials/deps are missing
# import vertexai
# from vertexai.generative_models import GenerativeModel, GenerationConfig

PROJECT_ID = os.environ.get("GOOGLE_CLOUD_PROJECT") or os.environ.get("GCP_PROJECT")
VERTEX_REGION = os.environ.get("VERTEX_REGION", "asia-northeast1")
# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯åœ°åŸŸã§åˆ©ç”¨å¯èƒ½æ€§ã®é«˜ã„æ–°ã—ã„ ID ã‚’å„ªå…ˆã—ã€å¾Œæ–¹äº’æ›ã§ -flash ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
GEMINI_MODEL_NAME = os.environ.get("GEMINI_MODEL_NAME", "gemini-2.0-flash-lite")

import re

def clean_quiz_markdown(raw: str) -> str:
    # 1. å…ˆé ­ã®ã€Œã¯ã„ã€æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€ãªã©ã‚’å…¨éƒ¨æ¨ã¦ã¦
    #    æœ€åˆã® "### Q" ã‹ã‚‰å§‹ã‚ã‚‹
    lines = raw.splitlines()
    start_idx = 0
    for i, line in enumerate(lines):
        if line.strip().startswith("### Q"):
            start_idx = i
            break
    cleaned = "\n".join(lines[start_idx:]).strip()

    # 2. ã€Œ1. è³ªå•:ã€ã®ã‚ˆã†ãªç•ªå·è¡ŒãŒç´›ã‚Œã¦ã„ãŸã‚‰å‰Šã‚‹
    cleaned = re.sub(r"^\s*\d+\.\s*è³ªå•[:ï¼š].*$\n?", "", cleaned, flags=re.MULTILINE)

    return cleaned


_vertex_initialized = False
_model: Any = None


def _ensure_model():
    global _vertex_initialized, _model
    if _vertex_initialized and _model:
        return
    
    # Lazy import
    import vertexai
    from vertexai.generative_models import GenerativeModel

    if not PROJECT_ID:
        raise RuntimeError("GOOGLE_CLOUD_PROJECT/GCP_PROJECT is not set for Vertex AI")
    vertexai.init(project=PROJECT_ID, location=VERTEX_REGION)

    # ãƒ¢ãƒ‡ãƒ«åã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒªã‚¹ãƒˆï¼ˆç’°å¢ƒå¤‰æ•°ãŒå„ªå…ˆï¼‰
    # 2.0 ç³»ã®ã¿ã‚’ä½¿ç”¨
    candidates = [GEMINI_MODEL_NAME, "gemini-2.0-flash"]
    last_err = None
    for name in candidates:
        if not name:
            continue
        try:
            _model = GenerativeModel(name)
            _vertex_initialized = True
            return
        except Exception as e:
            last_err = e
            continue
    # ã“ã“ã¾ã§æ¥ãŸã‚‰åˆæœŸåŒ–å¤±æ•—
    raise RuntimeError(f"Failed to initialize Gemini model. Tried: {candidates}") from last_err


async def summarize_transcript(text: str, mode: str = "lecture") -> str:
    """
    Transcript ã‚’ Vertex AI (Gemini) ã§è¦ç´„ã™ã‚‹ã€‚
    """
    _ensure_model()
    from vertexai.generative_models import GenerationConfig

    prompt = _build_summary_prompt(text, mode)
    resp = await _model.generate_content_async(
        prompt,
        generation_config=GenerationConfig(
            temperature=0.6,
            max_output_tokens=2048,
        ),
    )
    return (resp.text or "").strip()


async def generate_quiz(text: str, mode: str = "lecture", count: int = 5) -> str:
    """
    ã‚¯ã‚¤ã‚ºã‚’ç”Ÿæˆã™ã‚‹ã€‚JSON æ–‡å­—åˆ—ã®å‡ºåŠ›ã‚’æœŸå¾…ã€‚
    """
    _ensure_model()
    from vertexai.generative_models import GenerationConfig
    prompt = _build_quiz_prompt(text, mode, count)
    resp = await _model.generate_content_async(
        prompt,
        generation_config=GenerationConfig(
            temperature=0.5,
            max_output_tokens=2048,
        ),
    )
    return (resp.text or "").strip()

async def generate_explanation(text: str, mode: str = "lecture") -> str:
    """
    Transcript ã‚’åŸºã«è¦ç‚¹ã®è§£èª¬ã‚’ Markdown ã§ç”Ÿæˆã™ã‚‹ã€‚
    """
    _ensure_model()
    from vertexai.generative_models import GenerationConfig
    prompt = _build_explanation_prompt(text, mode)
    resp = await _model.generate_content_async(
        prompt,
        generation_config=GenerationConfig(
            temperature=0.4,
            max_output_tokens=2048,
        ),
    )
    return (resp.text or "").strip()


async def generate_playlist_timeline(
    text: str,
    segments: Optional[List[dict]] = None,
    duration_sec: Optional[float] = None
) -> str:
    """
    å†ç”Ÿãƒªã‚¹ãƒˆ(ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³)ã‚’ JSON æ–‡å­—åˆ—ã§ç”Ÿæˆã™ã‚‹ã€‚
    """
    _ensure_model()
    from vertexai.generative_models import GenerationConfig
    prompt = _build_playlist_prompt(text, segments=segments, duration_sec=duration_sec)
    resp = await _model.generate_content_async(
        prompt,
        generation_config=GenerationConfig(
            temperature=0.5,
            max_output_tokens=1024,
            response_mime_type="application/json",
        ),
    )
    # Gemini json mode returns text as JSON string
    return (resp.text or "").strip()

async def answer_question(text: str, question: str, mode: str = "lecture") -> dict:
    """
    ä¸ãˆã‚‰ã‚ŒãŸ transcript ã«åŸºã¥ãè³ªå•ã«å›ç­”ã™ã‚‹ã€‚
    çŸ­ã„å›ç­”ã¨æ ¹æ‹ ã¨ãªã‚‹å¼•ç”¨ç®‡æ‰€ï¼ˆæ–‡è„ˆæŠœç²‹ï¼‰ã‚’è¿”ã™ã€‚
    """
    _ensure_model()
    from vertexai.generative_models import GenerationConfig
    prompt = _build_qa_prompt(text, question, mode)
    resp = await _model.generate_content_async(
        prompt,
        generation_config=GenerationConfig(
            temperature=0.3,
            max_output_tokens=1024,
            response_mime_type="application/json",
        ),
    )
    try:
        return json.loads(resp.text or "{}")
    except Exception:
        return {"answer": (resp.text or "").strip(), "citations": []}


async def translate_text(text: str, target_lang: str) -> str:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šè¨€èªã«ç¿»è¨³ã™ã‚‹ã€‚
    """
    _ensure_model()
    from vertexai.generative_models import GenerationConfig
    
    prompt = f"""ã‚ãªãŸã¯ãƒ—ãƒ­ã®ç¿»è¨³è€…ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ {target_lang} ã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚
å‡ºåŠ›ã¯ç¿»è¨³çµæœã®ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ï¼ˆèª¬æ˜ã¯ä¸è¦ï¼‰ã€‚

=== ãƒ†ã‚­ã‚¹ãƒˆ ===
{text}
"""
    resp = await _model.generate_content_async(
        prompt,
        generation_config=GenerationConfig(
            temperature=0.3,
            max_output_tokens=2048,
        ),
    )
    return (resp.text or "").strip()


async def generate_highlights_and_tags(text: str, segments: Optional[List[dict]] = None) -> dict:
    """
    ãƒã‚¤ãƒ©ã‚¤ãƒˆã¨ã‚¿ã‚°ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    _ensure_model()
    from vertexai.generative_models import GenerationConfig
    prompt = _build_highlights_prompt(text, segments)
    resp = await _model.generate_content_async(
        prompt,
        generation_config=GenerationConfig(
            temperature=0.5,
            max_output_tokens=2048,
            response_mime_type="application/json",
        ),
    )
    try:
        data = json.loads(resp.text or "{}")
    except Exception:
        data = {}
    # æ­£è¦åŒ–: highlights ã¯ Highlight ãƒ¢ãƒ‡ãƒ«ã®å½¢ã«æƒãˆã‚‹
    highlights = []
    raw_highlights = data.get("highlights") or []
    for i, h in enumerate(raw_highlights):
        try:
            highlights.append({
                "id": h.get("id") or f"hl_{i}",
                "startSec": float(h.get("startSec", 0)),
                "endSec": float(h.get("endSec", 0)),
                "title": h.get("title") or h.get("summary") or "Highlight",
                "summary": h.get("summary"),
                "speakerIds": h.get("speakerIds") or [],
            })
        except Exception:
            continue

    tags = data.get("tags") or []
    return {"highlights": highlights, "tags": tags}


# ---------- Prompt Builders ---------- #

def _build_summary_prompt(text: str, mode: str) -> str:
    if mode == "lecture":
        return f"""ã‚ãªãŸã¯å„ªç§€ãªè¬›ç¾©ãƒãƒ¼ãƒˆä½œæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—ã‚’Markdownå½¢å¼ã§ã€å­¦ç”ŸãŒå¾©ç¿’ã—ã‚„ã™ã„å½¢ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚
- é‡è¦ãƒã‚¤ãƒ³ãƒˆã¯ç®‡æ¡æ›¸ãã§ç°¡æ½”ã«
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¤ªå­—ã§å¼·èª¿
- ä¸æ˜ç­ãªç®‡æ‰€ã¯ã€Œè¦ç¢ºèªã€ã¨è¨˜è¼‰

=== æ–‡å­—èµ·ã“ã— ===
{text}
"""
    return f"""ã‚ãªãŸã¯ä¼šè­°è­°äº‹éŒ²ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—ã‚’Markdownå½¢å¼ã§å®Ÿå‹™ã«ä½¿ãˆã‚‹è­°äº‹éŒ²ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚
- æ±ºå®šäº‹é …ã€TODOã€æ‡¸å¿µç‚¹ã‚’æ˜ç¢ºã«
- ç®‡æ¡æ›¸ãã§ç°¡æ½”ã«
- ä¸æ˜ç­ãªç®‡æ‰€ã¯ã€Œè¦ç¢ºèªã€ã¨è¨˜è¼‰

=== æ–‡å­—èµ·ã“ã— ===
{text}
"""


def _build_quiz_prompt(text: str, mode: str, count: int) -> str:
    return f"""ã‚ãªãŸã¯å­¦ç¿’ã‚¯ã‚¤ã‚ºä½œæˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—å†…å®¹ã‹ã‚‰ç†è§£åº¦ç¢ºèªã‚¯ã‚¤ã‚ºã‚’ {count} å•ä½œæˆã—ã¦ãã ã•ã„ã€‚

# é‡è¦:
- ä½™è¨ˆãªæŒ¨æ‹¶ã‚„èª¬æ˜æ–‡ã¯ä¸€åˆ‡æ›¸ã‹ãšã€
  **ã‚¯ã‚¤ã‚ºæœ¬ä½“ã® Markdown ã ã‘** ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
- ã€Œã¯ã„ã€æ‰¿çŸ¥ã—ã¾ã—ãŸã€ãªã©ã®å‰ç½®ãã¯æ›¸ã‹ãªã„ã§ãã ã•ã„ã€‚

# å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå¿…ãšã“ã®å½¢ã«ã™ã‚‹ï¼‰

å„å•ã¯æ¬¡ã®æ§‹é€ ã«ã—ã¦ãã ã•ã„ï¼š

### Q1
è³ªå•æ–‡ã‚’æ›¸ã

- A. é¸æŠè‚¢A
- B. é¸æŠè‚¢B
- C. é¸æŠè‚¢C
- D. é¸æŠè‚¢D

**Answer:** A
**Explanation:** ãªãœAãŒæ­£è§£ãªã®ã‹ã‚’1ã€œ2æ–‡ã§èª¬æ˜

### Q2
...

# åˆ¶ç´„
- å„å•é¡Œã¯ 4 æŠï¼ˆA/B/C/Dï¼‰
- æ­£è§£ã¯å¿…ãš Aã€œD ã®ã„ãšã‚Œã‹1ã¤
- æ—¥æœ¬èªã§è‡ªç„¶ã«æ›¸ã

=== ãƒ¢ãƒ¼ãƒ‰ ===
{mode}

=== æ–‡å­—èµ·ã“ã— ===
{text}
"""

def _build_explanation_prompt(text: str, mode: str) -> str:
    if mode == "lecture":
        return f"""ã‚ãªãŸã¯è¬›ç¾©å†…å®¹ã‚’å™›ã¿ç •ã„ã¦èª¬æ˜ã™ã‚‹ãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—ã‚’èª­ã¿ã€é‡è¦æ¦‚å¿µã‚’ç†è§£ã—ã‚„ã™ã„è§£èª¬ã¨ã—ã¦ Markdown ã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

- å†’é ­ã«3ã€œ5è¡Œã®è¦ç‚¹
- é‡è¦èªã¯ **å¤ªå­—**
- å¿…è¦ãªã‚‰çŸ­ã„å…·ä½“ä¾‹ã‚’è¿½åŠ 

=== æ–‡å­—èµ·ã“ã— ===
{text}
"""
    return f"""ã‚ãªãŸã¯ä¼šè­°å†…å®¹ã‚’ã‚ã‹ã‚Šã‚„ã™ãè§£èª¬ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—ã‚’èª­ã¿ã€èƒŒæ™¯ãƒ»æ„å›³ãƒ»è«–ç‚¹ã‚’æ•´ç†ã—ãŸè§£èª¬ã‚’ Markdown ã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

- å†’é ­ã«3ã€œ5è¡Œã®è¦ç‚¹
- é‡è¦èªã¯ **å¤ªå­—**
- å¿…è¦ãªã‚‰çŸ­ã„å…·ä½“ä¾‹ã‚’è¿½åŠ 

=== æ–‡å­—èµ·ã“ã— ===
{text}
"""


def _build_playlist_prompt(
    text: str,
    segments: Optional[List[dict]] = None,
    duration_sec: Optional[float] = None
) -> str:
    cues = _build_playlist_cues(segments)
    if duration_sec:
        if duration_sec <= 120:
            chapter_hint = "2ã€œ4"
            min_sec = 10
        elif duration_sec <= 600:
            chapter_hint = "3ã€œ6"
            min_sec = 20
        else:
            chapter_hint = "4ã€œ8"
            min_sec = 30
        duration_line = f"- åéŒ²æ™‚é–“ã¯ç´„ {duration_sec:.1f} ç§’ã€‚ç›®å®‰ã®ãƒãƒ£ãƒ—ã‚¿ãƒ¼æ•°ã¯ {chapter_hint} ä»¶"
    else:
        min_sec = 20
        duration_line = "- åéŒ²æ™‚é–“ãŒä¸æ˜ãªã®ã§ã€ãƒãƒ£ãƒ—ã‚¿ãƒ¼ã¯å†…å®¹é‡ã«å¿œã˜ã¦ 3ã€œ6 ä»¶"

    cues_block = ""
    if cues:
        cues_block = f"""
=== ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãæ–­ç‰‡ (å‚è€ƒ) ===
{cues}
"""

    return f"""ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—ã‚’ã€YouTube ã®ãƒãƒ£ãƒ—ã‚¿ãƒ¼ã®ã‚ˆã†ã«ã€Œæ„å‘³ã®ã¾ã¨ã¾ã‚Šã€ã§å†ç”Ÿãƒªã‚¹ãƒˆã«åˆ†å‰²ã—ã¦ãã ã•ã„ã€‚
JSON é…åˆ—ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚å½¢å¼:
[
  {{"startSec": 0.0, "endSec": 90.0, "title": "å°å…¥", "summary": "å†…å®¹è¦ç´„", "confidence": 0.9}},
  ...
]
ãƒ«ãƒ¼ãƒ«:
- 5ç§’åˆ»ã¿ã®æ©Ÿæ¢°çš„ãªåˆ†å‰²ã¯ç¦æ­¢
- startSec/endSec ã¯ç§’å˜ä½ï¼ˆæµ®å‹•å°æ•°ï¼‰
- 1ãƒãƒ£ãƒ—ã‚¿ãƒ¼ã®æœ€å°é•·ã¯ {min_sec} ç§’
- title ã¯çŸ­ãã€summary ã§è£œè¶³
- ã‚‚ã—ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãæ–­ç‰‡ãŒã‚ã‚‹å ´åˆã¯ã€ãã®æ™‚åˆ»ã«åˆã‚ã›ã¦ startSec/endSec ã‚’é¸ã¶
{duration_line}

=== æ–‡å­—èµ·ã“ã— ===
{text}
{cues_block}
"""


def _build_playlist_cues(segments: Optional[List[dict]], max_cues: int = 120, max_chars: int = 6000) -> str:
    if not segments:
        return ""

    cues = []
    buf_text = []
    buf_start = None
    buf_end = None
    for seg in segments:
        text = (seg.get("text") or "").strip()
        if not text:
            continue
        start = float(seg.get("startSec") or seg.get("start") or 0.0)
        end = float(seg.get("endSec") or seg.get("end") or 0.0)
        if buf_start is None:
            buf_start = start
        buf_end = end
        if len(buf_text) < 6:
            buf_text.append(text)
        duration = (buf_end or 0.0) - (buf_start or 0.0)
        if duration >= 25 or sum(len(t) for t in buf_text) >= 120:
            cues.append({
                "start": buf_start,
                "end": buf_end,
                "text": " ".join(buf_text)
            })
            buf_text = []
            buf_start = None
            buf_end = None
        if len(cues) >= max_cues:
            break

    if buf_text and buf_start is not None and buf_end is not None:
        cues.append({
            "start": buf_start,
            "end": buf_end,
            "text": " ".join(buf_text)
        })

    lines = []
    total = 0
    for cue in cues:
        line = f"[{cue['start']:.1f}-{cue['end']:.1f}] {cue['text']}"
        if total + len(line) > max_chars:
            break
        lines.append(line)
        total += len(line)
    return "\n".join(lines)


def _build_qa_prompt(text: str, question: str, mode: str) -> str:
    return f"""ã‚ãªãŸã¯è­°äº‹éŒ²/è¬›ç¾©ãƒãƒ¼ãƒˆã®QAã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—ã«åŸºã¥ã„ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚
JSON ã®ã¿è¿”ã—ã¦ãã ã•ã„ã€‚å½¢å¼:
{{
  "answer": "çŸ­ã„å›ç­”ã€‚5æ–‡ä»¥å†…ã€‚",
  "citations": [
    {{"excerpt": "æ ¹æ‹ ã¨ãªã‚‹æŠœç²‹", "reason": "ãªãœã“ã®æŠœç²‹ãŒæ ¹æ‹ ã‹"}}
  ]
}}
- å›ç­”ã¯æ—¥æœ¬èªã§ã€äº‹å®Ÿã«åŸºã¥ãã€æ†¶æ¸¬ã¯é¿ã‘ã‚‹
- transcript ã«å­˜åœ¨ã—ãªã„æƒ…å ±ã¯ã€Œä¸æ˜ã€ã¨ç­”ãˆã‚‹

# ãƒ¢ãƒ¼ãƒ‰
{mode}

# è³ªå•
{question}

# æ–‡å­—èµ·ã“ã—
{text}
"""


def _build_summary_tags_prompt(text: str, mode: str, segments: Optional[List[dict]]) -> str:
    seg_json = ""
    if segments:
        try:
            seg_json = json.dumps(segments)[:6000]
        except Exception:
            seg_json = ""
    
    constraints = """
# åˆ¶ç´„
- summary.overview: 400ã€œ600æ–‡å­—ã§ä¼šè­°ã®èƒŒæ™¯ãƒ»ç›®çš„ãƒ»çµè«–ã‚’å«ã‚€å……å®Ÿã—ãŸæ¦‚è¦
- summary.decisions: æ±ºå®šäº‹é …ã‚’å…·ä½“çš„ã«åˆ—æŒ™ï¼ˆãªã‘ã‚Œã°ç©ºé…åˆ—ï¼‰
- summary.todos: ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ï¼ˆæ‹…å½“è€…ãƒ»æœŸé™ãŒã‚ã‚Œã°å«ã‚ã‚‹ï¼‰
- summary.discussionPoints: è­°è«–ã®ãƒã‚¤ãƒ³ãƒˆ3ã€œ5ä»¶
- summary.keywords: é‡è¦ãªå°‚é–€ç”¨èªãƒ»å›ºæœ‰åè©ã‚’6ä»¶ã¾ã§
- tags: 2ã€œ6æ–‡å­—ã®åè©å¥ã‚’4ä»¶ã¾ã§ï¼ˆãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ç”¨ã€#ã¯ä»˜ã‘ãªã„ï¼‰
- å°‚é–€ç”¨èªã¯å™›ã¿ç •ã„ã¦èª¬æ˜ã‚’åŠ ãˆã‚‹
- æ›–æ˜§ãªç™ºè¨€ã‚‚ã€Œã€œã¨ã„ã†æ„è¦‹ãŒã‚ã£ãŸã€ã¨å®¢è¦³çš„ã«è¨˜éŒ²
- è©±è€…ãŒç‰¹å®šã§ãã‚‹å ´åˆã¯ã€ŒAã•ã‚“ã¯ã€œã€ã®ã‚ˆã†ã«è¨˜è¼‰
""".strip()

    return f"""ã‚ãªãŸã¯ä¼æ¥­ã®è­°äº‹éŒ²ä½œæˆã®ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§ã™ã€‚
ä»¥ä¸‹ã®ä¼šè­°éŸ³å£°ã®æ–‡å­—èµ·ã“ã—ã‹ã‚‰ã€**èª°ãŒèª­ã‚“ã§ã‚‚ã™ãã«å†…å®¹ãŒæŠŠæ¡ã§ãã‚‹**ãƒªãƒƒãƒã§åˆ†ã‹ã‚Šã‚„ã™ã„è­°äº‹éŒ²ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

# å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆå¿…ãšã“ã® JSON ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ï¼‰
{{
  "summary": {{
    "overview": "ã€æ¦‚è¦ã€‘ã“ã®ä¼šè­°ã¯ã€‡ã€‡ã«ã¤ã„ã¦è­°è«–ã™ã‚‹ãŸã‚ã«é–‹å‚¬ã•ã‚Œã¾ã—ãŸã€‚ä¸»ãªè­°é¡Œã¯â–³â–³ã§ã€çµè«–ã¨ã—ã¦â–¡â–¡ãŒæ±ºå®šã—ã¾ã—ãŸã€‚å‚åŠ è€…ã‹ã‚‰ã¯Ã—Ã—ã¨ã„ã†æ„è¦‹ãŒå‡ºã•ã‚Œã€ä»Šå¾Œã®æ–¹é‡ã¨ã—ã¦â–½â–½ã‚’é€²ã‚ã‚‹ã“ã¨ã«ãªã‚Šã¾ã—ãŸã€‚ï¼ˆ400ã€œ600æ–‡å­—ç¨‹åº¦ã®å……å®Ÿã—ãŸè¦ç´„ï¼‰",
    "decisions": [
      "ã€æ±ºå®š1ã€‘ã€‡ã€‡ã‚’â–³â–³ã¾ã§ã«å®Ÿæ–½ã™ã‚‹",
      "ã€æ±ºå®š2ã€‘â–¡â–¡ã®æ–¹é‡ã§é€²ã‚ã‚‹"
    ],
    "todos": [
      "ã€TODOã€‘Aã•ã‚“: ã€‡ã€‡ã®è³‡æ–™ã‚’æ¥é€±ã¾ã§ã«æº–å‚™",
      "ã€TODOã€‘Bã•ã‚“: â–³â–³ã®èª¿æŸ»ã‚’å®Ÿæ–½"
    ],
    "discussionPoints": [
      "ã€‡ã€‡ã«ã¤ã„ã¦ã€ã‚³ã‚¹ãƒˆå‰Šæ¸›ã®è¦³ç‚¹ã‹ã‚‰â–³â–³æ¡ˆã¨â–¡â–¡æ¡ˆãŒæ¯”è¼ƒæ¤œè¨ã•ã‚ŒãŸ",
      "Ã—Ã—ã®å°å…¥æ™‚æœŸã«ã¤ã„ã¦ã€Q1ã¨Q2ã§æ„è¦‹ãŒåˆ†ã‹ã‚ŒãŸ"
    ],
    "keywords": ["å°‚é–€ç”¨èª1", "å›ºæœ‰åè©2", "é‡è¦æ¦‚å¿µ3"]
  }},
  "tags": ["ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå", "éƒ¨ç½²å", "ãƒˆãƒ”ãƒƒã‚¯"]
}}

{constraints}

# é‡è¦ãªæ³¨æ„äº‹é …
- ä¼šè­°ã«å‚åŠ ã—ã¦ã„ãªã„äººã§ã‚‚å†…å®¹ãŒç†è§£ã§ãã‚‹ã‚ˆã†ã«æ›¸ã
- ç•¥èªã‚„ç¤¾å†…ç”¨èªã¯æ­£å¼åç§°ã‚‚ä½µè¨˜ã™ã‚‹
- æ•°å­—ã‚„ãƒ‡ãƒ¼ã‚¿ã¯æ­£ç¢ºã«è¨˜éŒ²ã™ã‚‹
- ç™ºè¨€ã®æ„å›³ãŒä¸æ˜ç¢ºãªå ´åˆã¯ã€Œã€œã¨ã„ã†è¶£æ—¨ã®ç™ºè¨€ãŒã‚ã£ãŸã€ã¨è¨˜è¼‰
- ãƒã‚¬ãƒ†ã‚£ãƒ–ãªå†…å®¹ã‚‚å®¢è¦³çš„ã«è¨˜éŒ²ã™ã‚‹

# ãƒ¢ãƒ¼ãƒ‰
{mode}

# æ–‡å­—èµ·ã“ã—
{text}

# ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ (è©±è€…æƒ…å ±ãªã©)
{seg_json}
"""


def _normalize_tags(raw_tags: List[Any], keywords: List[Any], mode: str) -> List[str]:
    """ã‚¿ã‚°ã‚’æ­£è¦åŒ–ã—ã€ä¸è¶³æ™‚ã¯è£œå®Œã™ã‚‹"""
    tags: List[str] = []
    
    # 1. Clean raw tags
    import re
    cleaned_candidates = []
    
    # Merge sources: raw_tags -> keywords
    sources = list(raw_tags)
    if keywords:
        sources.extend(keywords)

    for t in sources:
        if not isinstance(t, str):
            continue
        s = t.strip()
        if not s:
            continue
        # Remove leading hashes
        if s.startswith("#"):
            s = s.lstrip("#").strip()
        
        # Remove trailing punctuation
        s = re.sub(r"[#ã€ã€‚,.!\s]+$", "", s)
        # Remove common suffixes like "ã®ãƒ†ã‚¹ãƒˆ", "ã®ç¢ºèª"
        s = re.sub(r"(ã®ãƒ†ã‚¹ãƒˆ|ã®ç¢ºèª|ãƒ†ã‚¹ãƒˆ|ç¢ºèª)$", "", s)
        
        if s:
            cleaned_candidates.append(s)

    # 3. Default fallback if absolutely empty
    if not cleaned_candidates:
        if mode == "meeting":
            cleaned_candidates = ["ä¼šè­°"]
        elif mode == "lecture":
            cleaned_candidates = ["è¬›ç¾©"]
        else:
            cleaned_candidates = ["ãƒ¡ãƒ¢"]
            
    # 4. Dedup and limit
    seen = set()
    deduped = []
    for t in cleaned_candidates:
        if t in seen:
            continue
        seen.add(t)
        deduped.append(t)
        if len(deduped) >= 4:
            break
            
    return deduped





async def generate_summary_and_tags(text: str, mode: str = "lecture", segments: Optional[List[dict]] = None) -> dict:
    """
    è¦ç´„ãƒ»ã‚¿ã‚°ã‚’1å›ã® Gemini å‘¼ã³å‡ºã—ã§ç”Ÿæˆã™ã‚‹ã€‚
    ï¼ˆä»¥å‰ã¯Playlistã‚‚æ··åœ¨ã—ã¦ã„ãŸãŒåˆ†é›¢ï¼‰
    """
    _ensure_model()
    from vertexai.generative_models import GenerationConfig
    # Use the new prompt builder (renamed to avoid confusion, or reused name)
    # I'll rename the builder above to _build_summary_tags_prompt
    prompt = _build_summary_tags_prompt(text, mode, segments)
    resp = await _model.generate_content_async(
        prompt,
        generation_config=GenerationConfig(
            temperature=0.6,
            max_output_tokens=4096,
            response_mime_type="application/json",
        ),
    )
    try:
        data = json.loads(resp.text or "{}")
    except Exception:
        data = {}

    summary_data = data.get("summary") or {}
    raw_tags = data.get("tags") or []
    
    # Ensure points/keywords/tags fallback
    overview = summary_data.get("overview") or ""
    points = summary_data.get("points") or []
    keywords = summary_data.get("keywords") or []

    # Fallback 1: Overview to points if points empty
    if not points and overview:
        try:
            sentences = overview.replace("ã€‚", "ã€‚\n").split("\n")
            points = [s.strip() for s in sentences if s.strip()][:3]
        except Exception:
            points = []
    
    # Fallback 2: Tags to keywords if keywords empty
    if not keywords and raw_tags:
        keywords = raw_tags[:5]
    
    # Fallback 3: Keywords to tags if tags empty
    if not raw_tags and keywords:
        raw_tags = keywords[:4]

    # Re-normalize tags with new potential source
    tags = _normalize_tags(raw_tags, keywords, mode)
    
    # Update summary data for response consistency
    summary_data["points"] = points
    summary_data["keywords"] = keywords

    summary_md = _summary_json_to_markdown(summary_data)

    return {
        "summaryMarkdown": summary_md,
        "tags": tags
    }



def _build_highlights_prompt(text: str, segments: Optional[List[dict]]) -> str:
    seg_json = ""
    if segments:
        try:
            seg_json = json.dumps(segments)[:4000]  # prompt sizeæŠ‘åˆ¶
        except Exception:
            seg_json = ""
    return f"""ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—ã‹ã‚‰é‡è¦ãªãƒã‚¤ãƒ©ã‚¤ãƒˆã¨ã‚¿ã‚°ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
JSON ã§è¿”ã—ã¦ãã ã•ã„ã€‚å½¢å¼:
{{
  "highlights": [
    {{"startSec": 0.0, "endSec": 30.0, "title": "è¦ç‚¹", "summary": "è©³ç´°", "speakerIds": []}},
    ...
  ],
  "tags": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2"]
}}
- startSec/endSec ã¯ç§’å˜ä½
- ã‚¿ã‚°ã¯æœ€å¤§5å€‹

=== æ–‡å­—èµ·ã“ã— ===
{text}

=== ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆã‚ã‚Œã°ï¼‰ ===
{seg_json}
"""


def _summary_json_to_markdown(summary: dict) -> str:
    if not summary:
        return ""
    overview = summary.get("overview") or ""
    decisions = summary.get("decisions") or []
    todos = summary.get("todos") or []
    discussion_points = summary.get("discussionPoints") or summary.get("points") or []
    keywords = summary.get("keywords") or []

    lines = []
    lines.append("## ğŸ“‹ ä¼šè­°ã‚µãƒãƒªãƒ¼")
    lines.append("")
    
    if overview:
        if isinstance(overview, list):
            lines.append("\n".join(str(o) for o in overview if o))
        else:
            cleaned = str(overview).replace("#", "").strip()
            lines.append(cleaned)
        lines.append("")

    if decisions:
        lines.append("### âœ… æ±ºå®šäº‹é …")
        for d in decisions:
            lines.append(f"- {d}")
        lines.append("")

    if todos:
        lines.append("### ğŸ“Œ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ")
        for t in todos:
            lines.append(f"- {t}")
        lines.append("")

    if discussion_points:
        lines.append("### ğŸ’¬ è­°è«–ã®ãƒã‚¤ãƒ³ãƒˆ")
        for p in discussion_points:
            lines.append(f"- {p}")
        lines.append("")

    if keywords:
        lines.append("### ğŸ”‘ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
        lines.append(", ".join(keywords))
        lines.append("")
        
    return "\n".join(lines).strip()
