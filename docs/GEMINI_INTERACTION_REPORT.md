# Gemini Interaction Report

This document details how the Classnote API interacts with Google Cloud Vertex AI (Gemini) models. It covers the specific features, prompt structures, and expected response formats.

**Current Implementation Date:** 2025-12-12
**Model Provider:** Vertex AI
**Default Model:** `gemini-2.0-flash-lite` (fallback to `gemini-2.0-flash`)

---

## 1. Summary, Playlist & Tags (Combined)
Used during standard session processing (e.g., after recording or device sync). Generates a summary, chapter timeline, and hashtags in a single pass to reduce latency and cost.

*   **Function:** `app.services.llm.generate_summary_playlist_tags`
*   **Called By:** `app.task_queue._run_local_summarize` (and Cloud Run task equivalent)

### Prompt
The prompt instructs Gemini to act as a note-taking assistant for either a "lecture" or "meeting". It requests a JSON response containing three keys: `summary`, `playlist`, and `tags`.

```text
あなたの会議/講義のプロフェッショナルなノート作成アシスタントです。以下の内容から (1) 充実した要約、(2) 詳細な再生リスト（チャプター）、(3) 的確なハッシュタグ を JSON で生成してください。

# 出力フォーマット（必ずこの JSON のみを返してください）
{
  "summary": {
    "overview": "会議や講義の全体像が掴める、300文字程度の具体的で充実した日本語の要約。",
    "points": ["議論された主要な論点や決定事項を具体的に記述したポイント1", "ポイント2", "ポイント3..."],
    "keywords": ["重要単語1", "重要単語2"]
  },
  "playlist": [
    {
      "startSec": 0,
      "endSec": 120,
      "title": "導入・アジェンダ確認",
      "description": "冒頭で本日のゴールを確認"
    }
  ],
  "tags": ["タグ1", "タグ2", "タグ3"]
}

# 制約
- playlist は 5〜15 個程度にまとめる
- title は20文字以内でシンプルに
- tags は最大4つ、短い日本語フレーズ
- startSec は発話開始秒を基準に推定
- summary.overview は全体の流れがわかるように、300文字程度の充実した日本語で記述する
- summary.points は議論のポイントや決定事項を詳細に5項目以上挙げる

# モード
{mode}

# 文字起こし
{text}

# セグメント (必要なら活用)
{seg_json}
```

### Response Format (JSON)
The raw JSON response is parsed and mapped to Firestore fields:
- `summaryMarkdown`: Generated from `summary.overview`, `summary.points`, and `summary.keywords`.
- `playlist`: List of objects mapped to `PlaylistItem` (`id` generated by backend, `startSec`, `endSec`, `title`, `summary`).
- `tags`: List of strings.

---

## 2. Quiz Generation
Generates a multiple-choice quiz based on the transcript to test understanding.

*   **Function:** `app.services.llm.generate_quiz`
*   **Called By:** `POST /sessions/{id}/quiz` (via `app.task_queue.enqueue_quiz_task`)

### Prompt
Requests 5 multiple-choice questions in strict Markdown format.

```text
あなたは学習クイズ作成アシスタントです。
以下の文字起こし内容から理解度確認クイズを {count} 問作成してください。

# 重要:
- 余計な挨拶や説明文は一切書かず、
  **クイズ本体の Markdown だけ** を返してください。
- 「はい、承知しました」などの前置きは書かないでください。

# 出力フォーマット（必ずこの形にする）
### Q1
質問文を書く

- A. 選択肢A
- B. 選択肢B
- C. 選択肢C
- D. 選択肢D

**Answer:** A
**Explanation:** なぜAが正解なのかを1〜2文で説明

### Q2
...
```

### Response Format (Markdown)
Returns a cleaned Markdown string (saved to `quizMarkdown` in Firestore).
Artifacts like "Yes, I understand..." or numbered headers like "1. Question:" are stripped by the backend `clean_quiz_markdown` function before saving.
The client parses this Markdown to build a structured UI.

**Note:** Quiz generation is skipped if `quizMarkdown` already exists for the session (Cost saving).

---

## 3. Question Answering (QA)
Answers a specific user question based on the transcript context, providing citations.

*   **Function:** `app.services.llm.answer_question`
*   **Called By:** `POST /sessions/{id}/qa`

### Prompt
Instructs Gemini to answer in JSON format with citations (excerpts).

```text
あなたは議事録/講義ノートのQAアシスタントです。以下の文字起こしに基づいて質問に答えてください。
JSON のみ返してください。形式:
{
  "answer": "短い回答。5文以内。",
  "citations": [
    {"excerpt": "根拠となる抜粋", "reason": "なぜこの抜粋が根拠か"}
  ]
}
- 回答は日本語で、事実に基づき、憶測は避ける
- transcript に存在しない情報は「不明」と答える

# モード
{mode}

# 質問
{question}

# 文字起こし
{text}
```

### Response Format (JSON)
```json
{
  "answer": "...",
  "citations": [
    { "excerpt": "...", "reason": "..." }
  ]
}
```

---

## 4. Highlights & Tags (Standalone)
Extracts key highlight segments and tags. This is a separate task from the main summary flow, often triggered manually or for deeper analysis.

*   **Function:** `app.services.llm.generate_highlights_and_tags`
*   **Called By:** `POST /sessions/{id}/highlights` (via task queue)

### Prompt
```text
以下の文字起こしから重要なハイライトとタグを抽出してください。
JSON で返してください。形式:
{
  "highlights": [
    {"startSec": 0.0, "endSec": 30.0, "title": "要点", "summary": "詳細", "speakerIds": []},
    ...
  ],
  "tags": ["キーワード1", "キーワード2"]
}
- startSec/endSec は秒単位
- タグは最大5個

=== 文字起こし ===
{text}

=== セグメント（あれば） ===
{seg_json}
```

### Response Format (JSON)
Parsed into `highlights` list (mapped to `Highlight` model) and `tags` list.

---

## 5. Playlist Timeline (Standalone)
Generates just the playlist chapters. Note: The combined Summary/Playlist function (#1) is preferred for efficiency, but this function exists for standalone execution.

*   **Function:** `app.services.llm.generate_playlist_timeline`
*   **Called By:** `app.task_queue.enqueue_playlist_task`

### Prompt
```text
以下の文字起こしを、再生リスト（タイムライン）として分割してください。
JSON 配列のみを返してください。形式:
[
  {"startSec": 0.0, "endSec": 30.0, "title": "導入", "summary": "内容要約", "confidence": 0.9},
  ...
]
- startSec/endSec は秒単位（浮動小数）
- title は短く、summary で補足

=== 文字起こし ===
{text}
```

### Response Format (JSON Array)
A list of objects representing playlist items.

---

## Configuration & Notes
- **Temperature:**
    - Summary/Playlist: `0.6` (Balanced creativity/accuracy)
    - Quiz: `0.7` (More creative)
    - Playlist (Standalone): `0.5`
    - QA: `0.3` (More deterministic/factual)
    - Highlights: `0.5`
- **Max Output Tokens:** Typically `2048` or `4096` depending on the task complexity.
- **Retry Logic:** Implemented in `ensure_model` to fallback from `gemini-2.0-flash-lite` to `gemini-2.0-flash` if initialization fails.
